\begin{frame}
\frametitle{Binary classifier}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm,
  thick,main node/.style={circle,fill=blue!20,draw,font=\sffamily\Large\bfseries}]
%
  \node[style={font=\sffamily\Large\bfseries}] (1)
  {\includegraphics[scale=0.14]{./pictures/kitten.png}};
  \onslide<3>{
    \node[main node] (2) [right of=1]
    {$h(\raisebox{-0.2cm}{\includegraphics[scale=0.06]{./pictures/kitten.png}})$};
    \node[main node] (3) [below right of=2] {$0$};
    \node[main node] (4) [above right of=2] {$1$};
  %
    \path[every node/.style={font=\sffamily\small}]
       (1) edge node [right] {} (2)
       (2) edge node [right] {} (3)
       (2) edge node [right] {} (4);
     }
  \onslide<2-3>{
    \node (inA) [right=0.5cm of 4] {$\in A$};
    \node (notinA) [right=0.5cm of 3] {$\notin A$};
  }
\end{tikzpicture}
\end{frame}

\begin{frame}
  \begin{center}
    \includegraphics[scale=0.2]{./pictures/logreg_db078.png}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Hypothesis function}
  $h_w:
  \left \{
    \begin{array}{ccc}
      \{0, 1\}^n & \to & \mathbb{N} \\
      (x_1, \ldots, x_{n}) & \mapsto &
      \displaystyle\sum_{i=1}^n{w_i x_i} \\
    \end{array}
  \right.$
\end{frame}

\begin{frame}[fragile]
  \begin{block}{Hypothesis function}
      \begin{lstlisting}
def h(x, w):
    sum = 0
    for i in range(len(x)):
        sum += w[i] * x[i]
    return sum
      \end{lstlisting}
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Notation}
  $
  \begin{array}{cc}
    \onslide<2>{
      &
      \left(
        \begin{matrix}
          x_1 \\
          \vdots \\
          x_n
        \end{matrix}
      \right) \\}
    &\\
    \onslide<2>{\left(
      \begin{matrix}
        w_1 & \ldots & w_{n}
      \end{matrix}
    \right)} & {\left( \displaystyle\sum_{i = 1}^n{w_i x_i} \right)}
  \end{array}
  $
\end{frame}

\begin{frame}[fragile]
  \hspace{2em}
  \begin{block}{Hypothesis}
    \begin{lstlisting}
def h(x, w):
    return transpose(w) * x
    \end{lstlisting}
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{Step function}
  To force the output of $h$ to be in $\{0, 1\}$, we use the Heaviside step function:
  \vspace{1cm}

  $g:
  \left \{
    \begin{array}{ccc}
      \mathbb{N} & \to & \{0, 1\} \\
      x & \mapsto &
      \begin{array}{cc}
        1 & $if $ x >= 0 \\
        0 & $otherwise$
      \end{array}
    \end{array}
  \right.$
\end{frame}

\begin{frame}
  \begin{center}
    \includegraphics[scale=0.4]{./pictures/step_function.png}
  \end{center}
\end{frame}

\begin{frame}[fragile]
  \begin{block}{Step function}
      \begin{lstlisting}
def g(x):
    if x >= 0:
        return 1
    else:
        return 0
      \end{lstlisting}
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \begin{block}{Step function}
      \begin{lstlisting}
def g(x):
    return x >= 0
      \end{lstlisting}
  \end{block}
\end{frame}


\begin{frame}
  \frametitle{}
  $h_w:
  \left \{
    \begin{array}{ccc}
      \{0, 1\}^n & \to & \{0, 1\} \\
      x & \mapsto &
      g(w^T x) \\
    \end{array}
  \right.$
\end{frame}

\begin{frame}[fragile]
  \begin{block}{}
      \begin{lstlisting}
def h(x, w):
    return g(transpose(w) * x)
      \end{lstlisting}
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{Example}
  image:
  \nolinebreak
  $
  \left(
    \begin{matrix}
      0 & 0 & \colorbox{gray}{1} & \colorbox{gray}{1} & 0 & 0 \\
      0 & \colorbox{gray}{1} & 0 & 0 & \colorbox{gray}{1} & 0 \\
      0 & \colorbox{gray}{1} & 0 & 0 & 0 & 0 \\
      0 & \colorbox{gray}{1} & 0 & 0 & 0 & 0 \\
      0 & \colorbox{gray}{1} & 0 & 0 & \colorbox{gray}{1} & 0 \\
      0 & 0 & \colorbox{gray}{1} & \colorbox{gray}{1} & 0 & 0
    \end{matrix}
  \right)
  $
  \newline
  weights:
  \nolinebreak
  $
  \only<1>{
    \left(
      \begin{matrix}
        w0 & w1 & w2 & w3 & w4 & w5 \\
        w6 & w7 & w8 & w9 & w10 & w11 \\
        w12 & w13 & w14 & w15 & w16 & w17 \\
        w18 & w19 & w20 & w21 & w22 & w23 \\
        w24 & w25 & w26 & w27 & w28 & w29 \\
        w30 & w31 & w32 & w33 & w34 & w35
      \end{matrix}
    \right)
  }
  \only<2>{
    \left(
    \begin{matrix}
      0 & 0 & \colorbox{gray}{1} & \colorbox{gray}{1} & 0 & 0 \\
      0 & \colorbox{gray}{1} & 0 & 0 & \colorbox{gray}{1} & 0 \\
      0 & \colorbox{gray}{1} & 0 & 0 & 0 & 0 \\
      0 & \colorbox{gray}{1} & 0 & 0 & 0 & 0 \\
      0 & \colorbox{gray}{1} & 0 & 0 & \colorbox{gray}{1} & 0 \\
      0 & 0 & \colorbox{gray}{1} & \colorbox{gray}{1} & 0 & 0
    \end{matrix}
    \right)
  }
  \only<3>{
    \left(
    \begin{matrix}
      -1 & -1 & \colorbox{gray}{1} & \colorbox{gray}{1} & -1 & -1 \\
      -1 & \colorbox{gray}{1} & -1 & -1 & \colorbox{gray}{1} & -1 \\
      -1 & \colorbox{gray}{1} & -1 & -1 & -1 & -1 \\
      -1 & \colorbox{gray}{1} & -1 & -1 & -1 & -1 \\
      -1 & \colorbox{gray}{1} & -1 & -1 & \colorbox{gray}{1} & -1 \\
      -1 & -1 & \colorbox{gray}{1} & \colorbox{gray}{1} & -1 & -1
    \end{matrix}
    \right)
  }
  $
\end{frame}

\begin{frame}
  \begin{tikzpicture}[shorten >=1pt,->,draw=black!50, node distance=2.5cm]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]
    \tikzstyle{neuron}=[circle,draw,minimum size=17pt,inner sep=0pt]

    \foreach \y in {1,2,3,4}
    \node[neuron, pin=left:$x\y$] (I-\y) at (0,-\y) {};

    \node[neuron,pin={[pin edge={->}]right:$y$}, right of=I-3] (O-1) at
    (1.2,-2.5) {$g(x \cdot w)$};

    \foreach \src in {1,2,3,4}
    \path (I-\src) edge (O-1);
  \end{tikzpicture}
\end{frame}

\begin{frame}
  \begin{itemize}
    \item Find a way to measure how well a parametric model predicts known
      data (the training set).
    \item Use that information to adjust the
      parameters and make the model more accurate
    \item Repeat until a "good enough" model is found
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{The error function}
  \begin{center}
    \begin{equation*}
      \begin{split}
        e(w) & =
        \left \{
          \begin{array}{cl}
            1 & $if $ h_w(x) \neq y \\
            0 & $if $ h_w(x) = y
          \end{array}
          \right.\\~\\
          & = |h_w(x) - y| \\~\\
        \end{split}
      \end{equation*}
    \end{center}
  \end{frame}

  \begin{frame}
    \begin{center}
      $E(w) = \displaystyle\sum_{i = 1}^n{|h_w(x^{(i)}) - y^{(i)}|}$ \\~\\
      "Add 1 for every labeled data where the model is wrong"
    \end{center}
  \end{frame}

  \begin{frame}
    \frametitle{Error function}
    \begin{center}
      \includegraphics[scale=0.22]{./pictures/error_abs.png}
    \end{center}
  \end{frame}

    \begin{frame}
      \frametitle{The logistic function}
      \begin{center}
        \includegraphics[scale=0.14]{./pictures/sigmoid.png}
      \end{center}
    \end{frame}

\begin{frame}
  \frametitle{The logistic function}
  $g:
  \left \{
    \begin{array}{ccc}
      \mathbb{R} & \to & \left]0, 1\right[ \\
      x & \mapsto & \frac{1}{1 + e^{-x}}
    \end{array}
  \right.$
\end{frame}

\begin{frame}
  \frametitle{The logistic function}
  $\frac{d}{dx}g(x) = g(x)(1 - g(x))$
\end{frame}

\begin{frame}[fragile]
  \begin{block}{Logistic function}
    \begin{lstlisting}
  def g(x):
      1 / (1 + exp(-x))
    \end{lstlisting}
  \end{block}
\end{frame}

\begin{frame}
  \begin{tikzpicture}[shorten >=1pt,->,draw=black!50, node distance=2.5cm]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]
    \tikzstyle{neuron}=[circle,draw,minimum size=17pt,inner sep=0pt]

    \foreach \y in {1,2,3,4}
    \node[neuron, pin=left:$x\y$] (I-\y) at (0,-\y) {};

    \node[neuron,pin={[pin edge={->}]right:$P(x \in A)$}, right of=I-3] (O-1) at
    (1.2,-2.5) {$g(x \cdot w)$};

    \foreach \src in {1,2,3,4}
    \path (I-\src) edge (O-1);
  \end{tikzpicture}
\end{frame}

  \begin{frame}
    \frametitle{The error function}
    \begin{center}
      \begin{equation*}
        \begin{split}
          e(w) & =
          \left \{
            \begin{array}{cl}
              -\log(h_w(x)) & $ if $ y = 1\\
              -\log(1 - h_w(x)) & $ if $ y = 0
            \end{array}
            \right.\\~\\
            & = -y \log(h_w(x)) - (1 - y) \log(1 - h_w(x))\\~\\
          \end{split}
        \end{equation*}
      \end{center}
    \end{frame}

    \begin{frame}
      \frametitle{Error function}
      \begin{center}
        \includegraphics[scale=0.22]{./pictures/error_function.png}
      \end{center}
    \end{frame}

    \begin{frame}
      \begin{equation*}
        \begin{split}
          \frac{\partial e}{\partial w\only<1>{_i}} & = \frac{\partial \displaystyle\sum_{i =
        1}^n{-y \log(h_w(x)) - (1 - y) \log(1 -
      h_w(x)})}{\partial w\only<1>{_i}} \\~\\
      & = x\only<1>{_i} \cdot (h_w(x) - y)\\~\\
      \onslide<2>{~}
\end{split}
  \end{equation*}
\end{frame}

\begin{frame}[fragile]
  \begin{block}{}
    \begin{lstlisting}
def gradient(x, y, w):
    return x * (h(x, w) - y)
    \end{lstlisting}
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \begin{block}{Gradient descent}
    \begin{lstlisting}
def learn(x, y, w, a):
    return w - a * gradient(x, y, w)
    \end{lstlisting}
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{Gradient descent}
  \begin{center}
    \includegraphics[scale=0.22]{./pictures/gradient_descent.png}
  \end{center}
\end{frame}

\begin{frame}
  \begin{center}
    \includegraphics[scale=0.2]{./pictures/logreg_db000.png}
  \end{center}
\end{frame}

\begin{frame}
  \begin{center}
    \includegraphics[scale=0.2]{./pictures/logreg_db001.png}
  \end{center}
\end{frame}

\begin{frame}
  \begin{center}
    \includegraphics[scale=0.2]{./pictures/logreg_db012.png}
  \end{center}
\end{frame}

\begin{frame}
  \begin{center}
    \includegraphics[scale=0.2]{./pictures/logreg_db078.png}
  \end{center}
\end{frame}

\begin{frame}
\begin{center}
  \frametitle{Bias}
  $
  \begin{array}{cc}
      &
      \left(
        \begin{matrix}
          \only<2>{w_0 \\}
          w_1 \\
          \vdots \\
          w_n
        \end{matrix}
      \right) \\
    &\\
    \left(
      \begin{matrix}
        \only<2>{1 &} x_1 & \ldots & x_{n}
      \end{matrix}
    \right) & {\left(x \cdot w \right)}
  \end{array}
  \hspace{2em}
  $
\only<1>{\includegraphics[scale=0.3]{./pictures/linear.png}}
\only<2>{\includegraphics[scale=0.3]{./pictures/affine.png}}
\end{center}
\end{frame}

\begin{frame}[fragile]
  \begin{block}{Logistic regression}
    \begin{lstlisting}
from numpy import exp, transpose

def g(x):
    return 1 / (1 + exp(-x))

def h(x, w):
    return g(transpose(w) * x)

def gradient(x, y, w):
    return x * (h(x, w) - y)

def learn(x, y, w, a):
    return w - a * gradient(x, y, w)
    \end{lstlisting}
  \end{block}
\end{frame}

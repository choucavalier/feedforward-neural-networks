\documentclass{beamer}

\usepackage{listings}
\usetheme{Warsaw}
\setbeamertemplate{footline}[frame number]
\usepackage[latin1]{inputenc}
\usepackage{verbatim}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{ifthen}
\usepackage[]{algorithm2e}
\DontPrintSemicolon
\SetAlgoBlockMarkers{begin}{end}

\lstset{language=python,
  basicstyle=\ttfamily,
  keywordstyle=\color{blue}\ttfamily,
breaklines=true,
escapeinside=||}

\def\xcolorversion{2.00}
\def\xkeyvalversion{1.8}
\usepackage[version=0.96]{pgf}
\usepackage{tikz}
\usetikzlibrary{arrows, positioning}
\title{Feedforward neural networks}
\author{Valentin `toogy' Iovene\\
Thibaud `zehir' Michaud}


\AtBeginSection[]
{
  \begin{frame}<beamer>
    \tableofcontents[
      currentsection,
      sectionstyle=show/shaded,
      subsectionstyle=show/shaded/hide
    ]
  \end{frame}
}

\AtBeginSubsection[]
{
  \begin{frame}<beamer>
    \tableofcontents[
      currentsection,
      sectionstyle=show/shaded,
      subsectionstyle=show/shaded/hide
    ]
  \end{frame}
}

\begin{document}
\maketitle

\section{Introduction}
\input{sections/01-introduction.tex}

\section{Logistic regression}
\input{sections/02-logistic-regression.tex}

\section{Single layer perceptron}
\input{sections/04-single-layer-perceptron.tex}

\section{Multilayer perceptron}
\input{sections/05-multilayer-perceptron.tex}

\section{Backpropagation algorithm}
\input{sections/06-backpropagation-algorithm.tex}

\section{Optimizations}
\input{sections/07-optimizations.tex}

\begin{frame}
  \begin{center}
    \Large{Conclusion}
  \end{center}
\end{frame}
\end{document}
